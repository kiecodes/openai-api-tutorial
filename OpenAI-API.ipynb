{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edcc77-88c4-4673-9364-03f05354d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave, struct, os\n",
    "from openai import OpenAI\n",
    "from pvrecorder import PvRecorder\n",
    "from playsound import playsound\n",
    "from IPython.display import Image, display\n",
    "\n",
    " # silence deprecation warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe0166-db4f-46e1-974e-c087df58830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<Your API Key>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1f9ad5f-aab4-473e-8bbd-1234729c3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.context = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a witty assistant, always answering with a Joke.\"},\n",
    "        ]\n",
    "\n",
    "    def chat(self, message):\n",
    "        self.context.append(\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        )\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=self.context\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "        self.context.append(\n",
    "            {\"role\": \"assistant\", \"content\": response_content}\n",
    "        )\n",
    "        self.show_face(response_content)\n",
    "        self.print_chat()\n",
    "        self.speak(response_content)\n",
    "\n",
    "    def speak(self, message, index=0):\n",
    "        speech_file_path = os.getcwd() + f\"/speech_{index}.mp3\"\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"tts-1-hd\",\n",
    "            voice=\"echo\",\n",
    "            input=message\n",
    "        )\n",
    "        response.stream_to_file(speech_file_path)\n",
    "        playsound(speech_file_path)\n",
    "\n",
    "    def record_audio(self, index=0):\n",
    "        recorder = PvRecorder(device_index=-1, frame_length=512)\n",
    "        audio = []\n",
    "        filepath = os.getcwd() + f\"/recorded_{index}.mp3\"\n",
    "        \n",
    "        try:\n",
    "            recorder.start()\n",
    "            print(\"Audio recording started ...\")\n",
    "            while True:\n",
    "                frame = recorder.read()\n",
    "                audio.extend(frame)\n",
    "        except KeyboardInterrupt:\n",
    "            recorder.stop()\n",
    "            print(\"Audio recording stopped ...\")\n",
    "            with wave.open(filepath, 'w') as f:\n",
    "                f.setparams((1, 2, 16000, 512, \"NONE\", \"NONE\"))\n",
    "                f.writeframes(struct.pack(\"h\" * len(audio), *audio))\n",
    "        finally:\n",
    "            recorder.delete()\n",
    "            return filepath\n",
    "\n",
    "    def transcribe(self, audio_path):\n",
    "        audio_file= open(audio_path, \"rb\")\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "        return transcript.text \n",
    "\n",
    "    def voicechat(self):\n",
    "        recorded_filepath = self.record_audio(index=len(self.context))\n",
    "        message = self.transcribe(recorded_filepath)\n",
    "        self.chat(message)\n",
    "\n",
    "    def show_face(self, message):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4-0125-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are a face describing system which describes the face of a funny person making a funny comment.\n",
    "\t\t\t\t\t\tYou receive the text the person is saying, please describe the face that would be fitting as a prompt to the stable diffusion image generation AI, DALLÂ·E.\n",
    "                \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "              ]\n",
    "        )\n",
    "        image_description = response.choices[0].message.content\n",
    "\n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=image_description,\n",
    "            size=\"1024x1024\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        \n",
    "        display(Image(url=response.data[0].url))\n",
    "\n",
    "    def print_chat(self):\n",
    "        for message in self.context:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                print(f'USER: {message[\"content\"]}')\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                print(f'BOT: {message[\"content\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fd23194-95d3-405e-9dc2-12c83eb8ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1760b-254a-428b-a8c1-d6dd05efea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.voicechat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
